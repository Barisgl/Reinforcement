import pygameimport randomimport numpy as npimport tensorflowfrom collections import dequefrom keras.models import Sequentialfrom keras.layers import Densefrom keras.optimizers import Adamimport osos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'WIDTH= 360HEIGHT= 360FPS= 30WHITE=(255,255,255)BLACK=(0,0,0)GREEN=(0,255,0)RED=(255,0,0)BLUE=(0,0,255)class Player (pygame.sprite.Sprite):    def __init__(self):        pygame.sprite.Sprite.__init__(self)        self.image=pygame.Surface((20,20))        self.image.fill(BLUE)        self.rect=self.image.get_rect()        self.radius=10        pygame.draw.circle(self.image, RED,  self.rect.center, self.radius)                self.rect.center=(WIDTH/2, HEIGHT/2)        self.rect.bottom=HEIGHT- 1                self.speedx=0                                #self.y_speed=5                #self.x_speed=3                            def update(self,action):        self.speedx=0        keystate=pygame.key.get_pressed()                        if keystate[pygame.K_LEFT] or action== 0 :            self.speedx= -4        elif keystate[pygame.K_RIGHT] or action== 1:            self.speedx=4        else:            self.speedx=0                    self.rect.x +=self.speedx                if self.rect.right>WIDTH:            self.rect.right=WIDTH                if self.rect.left < 0:            self.rect.left = 0                def getCoordinaates(self):        return (self.rect.x, self.rect.y)                        #self.rect.y += self.y_speed                #if self.rect.bottom > HEIGHT - 200:         #   self.y_speed = -5                            #if self.rect.top < 0 :         #   self.y_speed=5                  class Enemy(pygame.sprite.Sprite):        def __init__(self):        pygame.sprite.Sprite.__init__(self)                self.image=pygame.Surface((10,10))                self.image.fill(RED)                self.rect=self.image.get_rect()                self.radius=5        pygame.draw.circle(self.image, WHITE,  self.rect.center, self.radius)                self.rect.x=random.randrange(0,WIDTH-self.rect.width)                self.rect.y=random.randrange(2,6)                self.speedx=0        self.speedy=3    def update(self):        self.rect.x+=self.speedx        self.rect.y+=self.speedy                if self.rect.top > HEIGHT +10:            self.rect.x=random.randrange(0,WIDTH - self.rect.width)            self.rect.y=random.randrange(2,6)            self.speedy=3                def getCoordinaates(self) :         return (self.rect.x, self.rect.y)                                       class DQLAgent:    def __init__(self):        self.state_size=4        self.action_size=3        self.gamma=0.95        self.learning_rate=0.001                self.epilson=1        self.epilson_decay=0.995        self.epilson_min=0.01                self.memory=deque(maxlen=1000)        self.model=self.build_model()                    def bouild_model(self):                model=Sequential()        model.add(Dense(48,input_dim=self.state_size,activation="relu"))        model.add(Dense(self.action_size,activation="linear"))        model.compile(loss="mse", optimizer=Adam(lr=self.learning_rate))        return model        def remember (self,state,action, reward, next_state, done):        self.memory.append((state,action,reward,next_state,done))            def act(self,state):        state=np.array(state)        if np.random.rand() <=self.epsilon:            return random.randomrange(self.action_size)                act_values=self.model.predict(state)                return np.argmax(act_values[0])               # if random.uniform(0,1)<=self.epsilon:        #    return env.action_space.sample()        #else :         #   act_values=self.model.predict(state)          #  return np.argmax(act_values[0])                    def replay(self,batch_size):                if len(self.memory)<batch_size:            return                minibatch=random.sample(self.memory,batch_size)        for state,action,reward,next_state,done in minibatch:            state=np.array(state)            next_state=np.array(next_state)            if done:                target=reward                            else :                target=reward + self.gamma*np.amax(self.model.predict(next_state)[0])            train_target=self.model.predict(state)            train_target[0][action]=target            self.model.fit(state,train_target, verbose=0)                def adaptiveEGreedy(self):        if self.epsilon>self.epsilon_min:            self.epsilon*=self.epsilon_decay        class Env(pygame.sprite.Sprite):    def __init__(self):        pygame.sprite.Sprite.__init__(self)        self.all_sprite=pygame.sprite.Group()        self.enemy=pygame.sprite.Group()        self.player = Player()        self.all_sprite.add(self.player)        self.m1=Enemy()        self.m2=Enemy()        self.all_sprite.add(self.m1)        self.all_sprite.add(self.m2)        enemy.add(self.m1)        enemy.add(self.m2)                self.reward=0        self.total_reward=0                        self.done=False                 self.agent=DQLAgent()                    def findDistance(self,a,b):                d=a-b        return d            def step(self,action):                state_list=[]                self.player.update(action)                self.enemy.update()                next_player_state=self.player.getCoordinates()        next_m1_state=self.m1.getCoordinates()        next_m2_state=self.m1-getCoordinaates                        state_list.append(self.findDistance(next_player_state[0], next_m1_state[0]))        state_list.append(self.findDistance(next_player_state[1], next_m1_state[1]))        state_list.append(self.findDistance(next_player_state[0], next_m2_state[0]))        state_list.append(self.findDistance(next_player_state[1], next_m2_state[1]))                return [state_list]            def initialState(self):                pygame.sprite.Sprite.__init__(self)        self.all_sprite=pygame.sprite.Group()        self.enemy=pygame.sprite.Group()        self.player = Player()        self.all_sprite.add(self.player)        self.m1=Enemy()        self.m2=Enemy()        self.all_sprite.add(self.m1)        self.all_sprite.add(self.m2)        enemy.add(self.m1)        enemy.add(self.m2)                self.reward=0        self.total_reward=0                        self.done=False            state_list=[]                player_state=self.player.getCoordinates()        m1_state=self.m1.getCoordinates()        m2_state=self.m1.getCoordinaates                        state_list.append(self.findDistance(player_state[0], m1_state[0]))        state_list.append(self.findDistance(player_state[1], m1_state[1]))        state_list.append(self.findDistance(player_state[0], m2_state[0]))        state_list.append(self.findDistance(player_state[1], m2_state[1]))                return [state_list]                def run(self):                state=self.initialState()                                        running=True                batch_size=24        while running:            self.reward=2                                                clock.tick(FPS)                        for event in pygame.event.get():                if event.type==pygame.QUIT:                    running=False                                action=self.agent.act(state)            next_state=self.step(action)            self.total_reward += self.reward                                                                                hits=pygame.sprite.spritecollide(self.player, self.enemy, False, pygame.sprite.collide_circle)                         if hits:                self.reward=-150                self.total_reward+= self.reward                self.done=True                running=False                print("Total Reward : ", self.total_reward)                                            self.agent.remember(state,action,self.reward, next_state, self.done)                        state=next_state                                    self.agent.replay(batch_size)                        self.agent.adaptiveEGreedy                        screen.fill(GREEN)                         self.all_sprite.draw(screen)                         pygame.display.flip()        pygame.quit()if __name__=="_main__":    env=Env()    liste=[]    t=0    while True:        t +=1        print("Episode:",t)        liste.append(env.total_reward)              pygame.init()        screen=pygame.display.set_mode((WIDTH,HEIGHT))        pygame.display.set_caption("RL Game")        clock =pygame.time.Clock()        env.run()"""all_sprite=pygame.sprite.Group()player = Player()enemy=pygame.sprite.Group()m1=Enemy()m2=Enemy()all_sprite.add(player)all_sprite.add(m1)all_sprite.add(m2)enemy.add(m1)enemy.add(m2)""""""running=Truewhile running:    clock.tick(FPS)        for event in pygame.event.get():        if event.type==pygame.QUIT:            running=False                # all_sprite.update()        hits=pygame.sprite.spritecollide(player, enemy, False, pygame.sprite.collide_circle)        if hits:        running=False        print("game over")          screen.fill(GREEN)        all_sprite.draw(screen)        pygame.display.flip()    pygame.quit()"""